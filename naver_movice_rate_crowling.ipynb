{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp9Ocp6c3IA9kLswjsk8uQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhyeongmin-khu/MLMovieProj/blob/main/naver_movice_rate_crowling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfpHk8Z9_L-9"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "df = pd.read_csv('empty_movie_up.csv')\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"chrome-win64/chromedriver.exe\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "all_reviews_df=[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "        movie_title = row['Movie_Title']\n",
        "        release_date = datetime.strptime(row['Release_Date'], '%Y-%m-%d')\n",
        "        url = row['URL']\n",
        "\n",
        "        # 개봉일 전후 1,2,3주일 기간 설정\n",
        "\n",
        "        week1_end_date = (release_date + timedelta(days=6))\n",
        "        week2_end_date = (week1_end_date + timedelta(days=7))\n",
        "        week3_end_date = (week2_end_date + timedelta(days=7))\n",
        "        start_date = release_date\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            driver.get(url)\n",
        "            time.sleep(5)\n",
        "            try:\n",
        "                # Click on the area to load reviews\n",
        "                area_element = driver.find_element(By.CLASS_NAME, 'area_card_outer')\n",
        "                area_element.click()\n",
        "                time.sleep(2)  # Wait for content to load (adjust as needed)\n",
        "\n",
        "                # Find the specific element to scroll within\n",
        "                scrollable_element = driver.find_element(By.CLASS_NAME, 'lego_review_list')\n",
        "\n",
        "                # Scroll down within the specific element to load all reviews\n",
        "                last_height = driver.execute_script(\"return arguments[0].scrollHeight;\", scrollable_element)\n",
        "                while True:\n",
        "                    driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_element)\n",
        "                    time.sleep(1)  # Wait for content to load (adjust as needed)\n",
        "\n",
        "                    new_height = driver.execute_script(\"return arguments[0].scrollHeight;\", scrollable_element)\n",
        "                    if new_height == last_height:\n",
        "                        break\n",
        "                    last_height = new_height\n",
        "\n",
        "                page_source = driver.page_source\n",
        "\n",
        "\n",
        "                soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "                review_items = soup.find_all('li', class_='area_card _item')\n",
        "\n",
        "                # Create a list to store review data\n",
        "                reviews_data = []\n",
        "\n",
        "                for review in review_items:\n",
        "                    rating_id = review['data-rating-id']\n",
        "                    movie_code = review['data-movie-code']\n",
        "                    rating_point_type = review['data-rating-point-type']\n",
        "                    writer_id = review['data-report-writer-id']\n",
        "                    report_title = review['data-report-title']\n",
        "                    report_time = review['data-report-time']\n",
        "\n",
        "                    # Extract the last character as the rating value\n",
        "                    rating_value = review.find('div', class_='area_text_box').text.strip()[-1]\n",
        "\n",
        "                    if rating_value =='0':\n",
        "                        rating_value='10'\n",
        "                    report_time=report_time[:8]\n",
        "                    report_time= datetime.strptime(report_time, '%Y%m%d')\n",
        "\n",
        "\n",
        "                    reviews_data.append({\n",
        "                        \"Rating ID\": rating_id,\n",
        "                        \"Movie Code\": movie_code,\n",
        "                        \"Rating Point Type\": rating_point_type,\n",
        "                        \"Writer ID\": writer_id,\n",
        "                        \"Report Title\": report_title,\n",
        "                        \"Report Time\": report_time,\n",
        "                        \"Rating\": rating_value\n",
        "                    })\n",
        "\n",
        "                    # Create a DataFrame from the reviews data\n",
        "                reviews_df = pd.DataFrame(reviews_data)\n",
        "\n",
        "                # Calculate average ratings for each week\n",
        "                week1_avg = reviews_df[(reviews_df['Report Time'] >= start_date) & (reviews_df['Report Time'] <= week1_end_date)]['Rating'].astype(float).mean()\n",
        "                week2_avg = reviews_df[(reviews_df['Report Time'] >= start_date) & (reviews_df['Report Time'] <= week2_end_date)]['Rating'].astype(float).mean()\n",
        "                week3_avg = reviews_df[(reviews_df['Report Time'] >= start_date) & (reviews_df['Report Time'] <= week3_end_date)]['Rating'].astype(float).mean()\n",
        "\n",
        "                # Append the results to the all_reviews_df\n",
        "                all_reviews_df.append({\n",
        "                    'Movie_Title': movie_title,\n",
        "                    'Week1_Avg': week1_avg,\n",
        "                    'Week2_Avg': week2_avg,\n",
        "                    'Week3_Avg': week3_avg\n",
        "                })\n",
        "            except:\n",
        "                all_reviews_df.append({\n",
        "                    'Movie_Title': movie_title,\n",
        "                    'Week1_Avg': 0,\n",
        "                    'Week2_Avg': 0,\n",
        "                    'Week3_Avg': 0\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(\"An unexpected error occurred:\", e)\n",
        "\n",
        "\n",
        "driver.quit()\n",
        "all_reviews_df_good = pd.DataFrame(all_reviews_df)\n",
        "# Save the DataFrame to an Excel file\n",
        "excel_filename = \"empty_movie_up_final0608.csv\"\n",
        "all_reviews_df_good.to_csv(excel_filename, index=False)\n",
        "\n",
        "print(f\"Reviews with ratings saved to {excel_filename}\")"
      ]
    }
  ]
}