{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO73BvZvJDnIqzmef29nibg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhyeongmin-khu/MLMovieProj/blob/main/week3%EC%98%88%EC%B8%A1_nonlinear_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znKMCO9e9Ol8"
      },
      "outputs": [],
      "source": [
        "#RandomForestRegressor 최적의 하이퍼파라미터 탐색\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# 난수 생성기의 시드 고정\n",
        "np.random.seed(42)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "file_path = '0530_dataset/preprosessing_ver15.csv'  # 파일 경로를 지정하세요\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 타겟 변수 설정\n",
        "target_variable = 'w3_ac_au'\n",
        "\n",
        "# 기본 피처 세트 정의 (사용자가 제공)\n",
        "user_selected_features = [\n",
        "   'w2_ac_au', 'w2_rank', 'w2_av_sc', 'w2_av_sales', 'w2_df_rank',\n",
        "   'di_ca_au_y3', 'Distributors_mv_au_y3', 'actor_mv_au_y3', 'Week2_Avg',\n",
        "   'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'Is_High_Season',\n",
        "   'Others', 'USA', 'Korea'\n",
        "]\n",
        "\n",
        "# 제공된 기본 피처 세트를 사용\n",
        "X = df[user_selected_features].copy()\n",
        "y = df[target_variable]\n",
        "\n",
        "# RFE를 사용한 피처 선택\n",
        "model = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "fit = rfe.fit(X, y)\n",
        "\n",
        "# 선택된 피처들\n",
        "selected_features = np.array(user_selected_features)[fit.support_]\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "# 선택된 피처들만 사용하여 데이터프레임 구성\n",
        "X_selected = X.loc[:, fit.support_]\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 및 상위 오차 데이터 추출\n",
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "rmse_scores = []\n",
        "mape_scores = []\n",
        "r_squared_scores = []\n",
        "\n",
        "# 오차 비율이 큰 상위 데이터를 저장할 리스트\n",
        "top_errors = []\n",
        "\n",
        "for train_idx, val_idx in k_fold.split(X_selected):\n",
        "    X_train_fold, X_val_fold = X_selected.iloc[train_idx], X_selected.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "\n",
        "    mae_scores.append(mean_absolute_error(y_val_fold, y_val_pred))\n",
        "    mse_scores.append(mean_squared_error(y_val_fold, y_val_pred))\n",
        "    rmse_scores.append(np.sqrt(mean_squared_error(y_val_fold, y_val_pred)))\n",
        "    mape_scores.append(np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100)\n",
        "    r_squared_scores.append(r2_score(y_val_fold, y_val_pred))\n",
        "\n",
        "    # 오차 비율 계산 및 상위 오차 데이터 저장\n",
        "    error_ratios = np.abs((y_val_fold - y_val_pred) / y_val_fold)\n",
        "    top_error_idx = np.argmax(error_ratios)\n",
        "    top_errors.append({\n",
        "        'Actual': y_val_fold.iloc[top_error_idx],\n",
        "        'Predicted': y_val_pred[top_error_idx],\n",
        "        'Error Ratio': error_ratios.iloc[top_error_idx]\n",
        "    })\n",
        "\n",
        "# 교차 검증 평가 결과 출력\n",
        "results = {\n",
        "    'MAE': np.mean(mae_scores),\n",
        "    'MSE': np.mean(mse_scores),\n",
        "    'RMSE': np.mean(rmse_scores),\n",
        "    'MAPE': np.mean(mape_scores),\n",
        "    'R2': np.mean(r_squared_scores)\n",
        "}\n",
        "print(results)\n",
        "\n",
        "# 피처 중요도 출력\n",
        "importances = model.feature_importances_\n",
        "for feature, importance in zip(selected_features, importances):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "# 상위 오차 비율 데이터 출력\n",
        "top_errors_sorted = sorted(top_errors, key=lambda x: x['Error Ratio'], reverse=True)[:10]\n",
        "print(\"Top 10 Error Ratios:\")\n",
        "for error_data in top_errors_sorted:\n",
        "    print(f\"Actual: {error_data['Actual']}, Predicted: {error_data['Predicted']}, Error Ratio: {error_data['Error Ratio']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNeighborsRegressor 최적의 하이퍼파라미터 탐색\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
        "\n",
        "# 난수 생성기의 시드 고정\n",
        "np.random.seed(42)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "file_path = '0530_dataset/preprosessing_ver15.csv'  # 파일 경로를 지정하세요\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 타겟 변수 설정\n",
        "target_variable = 'w3_ac_au'\n",
        "\n",
        "# 숫자형 데이터만 선택\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# 제외할 열들\n",
        "exclude_cols = ['w1_slope', 'w1_df_rank', 'w1_mean_diff', 'w2_slope', 'w2_df_rank', 'w2_mean_diff']\n",
        "\n",
        "# 범주형 열들 (예를 들어 사용자가 지정한 범주형 열들)\n",
        "categorical_cols = ['Is_High_Season', 'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'USA', 'Korea', 'Others']\n",
        "\n",
        "# 제외할 열들을 뺀 나머지 열들\n",
        "cols_to_transform = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# 나머지 열들에 대해 0 이하의 값을 작은 양수로 대체\n",
        "df[cols_to_transform] = df[cols_to_transform].apply(lambda x: np.where(x > 0, x, 1e-6))\n",
        "\n",
        "# 기본 피처 세트 정의 (사용자가 제공)\n",
        "user_selected_features = [\n",
        "   'w2_ac_au', 'w2_rank', 'w2_av_sc', 'w2_av_sales',  'w2_df_rank',\n",
        "   'di_ca_au_y3', 'Distributors_mv_au_y3', 'actor_mv_au_y3', 'Week2_Avg',\n",
        "   'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'Is_High_Season',\n",
        "   'Others', 'USA', 'Korea'\n",
        "]\n",
        "\n",
        "# 제공된 기본 피처 세트를 사용\n",
        "X_transformed = df[user_selected_features].copy()\n",
        "\n",
        "# 로그 변환 (exclude_cols 제외)\n",
        "numeric_features_to_log = [col for col in user_selected_features if col not in categorical_cols + exclude_cols]\n",
        "X_transformed[numeric_features_to_log] = np.log1p(X_transformed[numeric_features_to_log])\n",
        "y_transformed = np.log1p(df[target_variable])\n",
        "\n",
        "# 수치형 열만 스케일링\n",
        "numeric_features = [col for col in user_selected_features if col not in categorical_cols]\n",
        "scaler = StandardScaler()\n",
        "X_numeric_scaled = scaler.fit_transform(X_transformed[numeric_features])\n",
        "\n",
        "# 스케일링 된 수치형 데이터와 범주형 데이터를 다시 결합\n",
        "X_combined = np.concatenate([X_numeric_scaled, X_transformed[categorical_cols].values], axis=1)\n",
        "\n",
        "# 전체 피처 이름 리스트\n",
        "combined_feature_names = numeric_features + categorical_cols\n",
        "\n",
        "# KNN 회귀 모델 정의\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# 그리드 서치로 최적의 하이퍼파라미터 탐색\n",
        "param_grid = {'n_neighbors': np.arange(1, 31)}\n",
        "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring=scorer)\n",
        "\n",
        "# 그리드 서치 수행\n",
        "grid_search.fit(X_combined, y_transformed)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best MAPE: {-grid_search.best_score_}\")\n",
        "\n",
        "# 최적의 모델로 예측 수행\n",
        "best_knn = grid_search.best_estimator_\n",
        "y_pred = best_knn.predict(X_combined)\n",
        "y_pred_original = np.expm1(y_pred)\n",
        "y_true_original = np.expm1(y_transformed)\n",
        "\n",
        "# 전체 데이터에서 MAPE 계산\n",
        "overall_mape = mean_absolute_percentage_error(y_true_original, y_pred_original)\n",
        "print(f\"Overall MAPE: {overall_mape}\")\n",
        "\n",
        "# 피처 중요도는 KNN에서는 제공되지 않으므로 생략\n",
        "\n",
        "# 최적의 하이퍼파라미터 찾기\n",
        "n_neighbors = grid_search.best_params_['n_neighbors']\n",
        "print(f\"Optimal number of neighbors: {n_neighbors}\")\n",
        "\n",
        "# 상위 오차 비율 데이터 출력\n",
        "error_ratios = np.abs((y_true_original - y_pred_original) / y_true_original)\n",
        "top_errors_idx = np.argsort(error_ratios)[-10:]\n",
        "top_errors = pd.DataFrame({\n",
        "    'Actual': y_true_original[top_errors_idx],\n",
        "    'Predicted': y_pred_original[top_errors_idx],\n",
        "    'Error Ratio': error_ratios[top_errors_idx]\n",
        "})\n",
        "\n",
        "print(\"Top 10 Error Ratios:\")\n",
        "print(top_errors)\n"
      ],
      "metadata": {
        "id": "eFyuimMn-NWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xgb 최적의 하이퍼파라미터 탐색\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# 난수 생성기의 시드 고정\n",
        "np.random.seed(42)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "file_path = '0530_dataset\\preprosessing_ver15.csv'  # 파일 경로를 지정하세요\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 타겟 변수 설정\n",
        "target_variable = 'w3_ac_au'\n",
        "\n",
        "# 숫자형 데이터만 선택\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# 제외할 열들\n",
        "exclude_cols = ['w1_slope', 'w1_df_rank', 'w1_mean_diff', 'w2_slope', 'w2_df_rank', 'w2_mean_diff']\n",
        "\n",
        "# 범주형 열들 (예를 들어 사용자가 지정한 범주형 열들)\n",
        "categorical_cols = ['Is_High_Season', 'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'USA', 'Korea', 'Others']\n",
        "\n",
        "# 제외할 열들을 뺀 나머지 열들\n",
        "cols_to_transform = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# 나머지 열들에 대해 0 이하의 값을 작은 양수로 대체\n",
        "df[cols_to_transform] = df[cols_to_transform].apply(lambda x: np.where(x > 0, x, 1e-6))\n",
        "\n",
        "# 기본 피처 세트 정의 (사용자가 제공)\n",
        "user_selected_features = [\n",
        "    'w2_ac_au', 'w2_rank', 'w2_av_sc', 'w2_av_sales',  'w2_df_rank',\n",
        "    'di_ca_au_y3', 'Distributors_mv_au_y3', 'actor_mv_au_y3', 'Week2_Avg',\n",
        "    'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'Is_High_Season',\n",
        "    'Others', 'USA', 'Korea'\n",
        "]\n",
        "\n",
        "# 제공된 기본 피처 세트를 사용\n",
        "X_transformed = df[user_selected_features].copy()\n",
        "\n",
        "# 로그 변환 (exclude_cols 제외)\n",
        "numeric_features_to_log = [col for col in user_selected_features if col not in categorical_cols + exclude_cols]\n",
        "X_transformed[numeric_features_to_log] = np.log1p(X_transformed[numeric_features_to_log])\n",
        "y_transformed = np.log1p(df[target_variable])\n",
        "\n",
        "# 수치형 열만 스케일링\n",
        "numeric_features = [col for col in user_selected_features if col not in categorical_cols]\n",
        "scaler = StandardScaler()\n",
        "X_numeric_scaled = scaler.fit_transform(X_transformed[numeric_features])\n",
        "\n",
        "# 스케일링 된 수치형 데이터와 범주형 데이터를 다시 결합\n",
        "X_combined = np.concatenate([X_numeric_scaled, X_transformed[categorical_cols].values], axis=1)\n",
        "\n",
        "# 전체 피처 이름 리스트\n",
        "combined_feature_names = numeric_features + categorical_cols\n",
        "\n",
        "# XGBoost 회귀 모델 정의\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# 그리드 서치로 최적의 하이퍼파라미터 탐색\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring=scorer)\n",
        "\n",
        "# 그리드 서치 수행\n",
        "grid_search.fit(X_combined, y_transformed)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best MAPE: {-grid_search.best_score_}\")\n"
      ],
      "metadata": {
        "id": "f0jbb-WM-P4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForestRegressor예측\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# 난수 생성기의 시드 고정\n",
        "np.random.seed(42)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "file_path = '0530_dataset/preprosessing_ver15.csv'  # 파일 경로를 지정하세요\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 타겟 변수 설정\n",
        "target_variable = 'w3_ac_au'\n",
        "\n",
        "# 숫자형 데이터만 선택\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# 제외할 열들\n",
        "exclude_cols = ['w1_slope', 'w1_df_rank', 'w1_mean_diff', 'w2_slope', 'w2_df_rank', 'w2_mean_diff']\n",
        "\n",
        "# 범주형 열들 (예를 들어 사용자가 지정한 범주형 열들)\n",
        "categorical_cols = ['Is_High_Season', 'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'USA', 'Korea', 'Others']\n",
        "\n",
        "# 제외할 열들을 뺀 나머지 열들\n",
        "cols_to_transform = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# 나머지 열들에 대해 0 이하의 값을 작은 양수로 대체\n",
        "df[cols_to_transform] = df[cols_to_transform].apply(lambda x: np.where(x > 0, x, 1e-6))\n",
        "\n",
        "# 기본 피처 세트 정의 (사용자가 제공)\n",
        "user_selected_features = [\n",
        "   'w2_ac_au', 'w2_rank', 'w2_av_sc', 'w2_av_sales', 'w2_df_rank',\n",
        "   'di_ca_au_y3', 'Distributors_mv_au_y3', 'actor_mv_au_y3', 'Week2_Avg',\n",
        "   'Over_12', 'Over_15', 'General_Audience', 'No_Youth', 'Is_High_Season',\n",
        "   'Others', 'USA', 'Korea'\n",
        "]\n",
        "\n",
        "# 제공된 기본 피처 세트를 사용\n",
        "X_transformed = df[user_selected_features].copy()\n",
        "\n",
        "# 로그 변환 (exclude_cols 제외)\n",
        "numeric_features_to_log = [col for col in user_selected_features if col not in categorical_cols + exclude_cols]\n",
        "X_transformed[numeric_features_to_log] = np.log1p(X_transformed[numeric_features_to_log])\n",
        "y_transformed = np.log1p(df[target_variable])\n",
        "\n",
        "# 수치형 열만 스케일링\n",
        "numeric_features = [col for col in user_selected_features if col not in categorical_cols]\n",
        "scaler = StandardScaler()\n",
        "X_numeric_scaled = scaler.fit_transform(X_transformed[numeric_features])\n",
        "\n",
        "# 스케일링 된 수치형 데이터와 범주형 데이터를 다시 결합\n",
        "X_combined = np.concatenate([X_numeric_scaled, X_transformed[categorical_cols].values], axis=1)\n",
        "\n",
        "# 전체 피처 이름 리스트\n",
        "combined_feature_names = numeric_features + categorical_cols\n",
        "\n",
        "# RFE를 사용한 피처 선택\n",
        "model = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "fit = rfe.fit(X_combined, y_transformed)\n",
        "\n",
        "# 선택된 피처들\n",
        "selected_features = np.array(combined_feature_names)[fit.support_]\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "# 선택된 피처들만 사용하여 데이터프레임 구성\n",
        "X_selected = X_combined[:, fit.support_]\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 및 상위 오차 데이터 추출\n",
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "rmse_scores = []\n",
        "mape_scores = []\n",
        "r_squared_scores = []\n",
        "\n",
        "# 오차 비율이 큰 상위 데이터를 저장할 리스트\n",
        "top_errors = []\n",
        "\n",
        "for train_idx, val_idx in k_fold.split(X_selected):\n",
        "    X_train_fold, X_val_fold = X_selected[train_idx], X_selected[val_idx]\n",
        "    y_train_fold, y_val_fold = y_transformed.iloc[train_idx], y_transformed.iloc[val_idx]\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "\n",
        "    # 예측값과 실제값을 원래 스케일로 되돌리기\n",
        "    y_val_pred_exp = np.expm1(y_val_pred)\n",
        "    y_val_exp = np.expm1(y_val_fold)\n",
        "\n",
        "    mae_scores.append(mean_absolute_error(y_val_exp, y_val_pred_exp))\n",
        "    mse_scores.append(mean_squared_error(y_val_exp, y_val_pred_exp))\n",
        "    rmse_scores.append(np.sqrt(mean_squared_error(y_val_exp, y_val_pred_exp)))\n",
        "    mape_scores.append(np.mean(np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)) * 100)\n",
        "    r_squared_scores.append(r2_score(y_val_exp, y_val_pred_exp))\n",
        "\n",
        "    # 오차 비율 계산 및 상위 오차 데이터 저장\n",
        "    error_ratios = np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)\n",
        "    top_error_idx = np.argmax(error_ratios)\n",
        "    top_errors.append({\n",
        "        'Actual': y_val_exp.iloc[top_error_idx],\n",
        "        'Predicted': y_val_pred_exp[top_error_idx],\n",
        "        'Error Ratio': error_ratios.iloc[top_error_idx]\n",
        "    })\n",
        "\n",
        "# 교차 검증 평가 결과 출력\n",
        "results = {\n",
        "    'MAE': np.mean(mae_scores),\n",
        "    'MSE': np.mean(mse_scores),\n",
        "    'RMSE': np.mean(rmse_scores),\n",
        "    'MAPE': np.mean(mape_scores),\n",
        "    'R2': np.mean(r_squared_scores)\n",
        "}\n",
        "print(results)\n",
        "\n",
        "# 피처 중요도 출력\n",
        "importances = model.feature_importances_\n",
        "for feature, importance in zip(selected_features, importances):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "# 상위 오차 비율 데이터 출력\n",
        "top_errors_sorted = sorted(top_errors, key=lambda x: x['Error Ratio'], reverse=True)[:10]\n",
        "print(\"Top 10 Error Ratios:\")\n",
        "for error_data in top_errors_sorted:\n",
        "    print(f\"Actual: {error_data['Actual']}, Predicted: {error_data['Predicted']}, Error Ratio: {error_data['Error Ratio']}\")\n"
      ],
      "metadata": {
        "id": "HchnnTEe-RiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNeighborsRegressor예측\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# KNN 모델 사용\n",
        "knn_model = KNeighborsRegressor(n_neighbors=8)\n",
        "\n",
        "# SequentialFeatureSelector 사용\n",
        "sfs = SequentialFeatureSelector(knn_model, n_features_to_select=10, direction='forward')\n",
        "sfs.fit(X_combined, y_transformed)\n",
        "\n",
        "# 선택된 피처들\n",
        "selected_features_sfs = np.array(combined_feature_names)[sfs.get_support()]\n",
        "print(f\"Selected features with SequentialFeatureSelector: {selected_features_sfs}\")\n",
        "\n",
        "# 선택된 피처들만 사용하여 데이터프레임 구성\n",
        "X_selected_sfs = X_combined[:, sfs.get_support()]\n",
        "\n",
        "# 교차 검증을 통한 KNN 모델 평가\n",
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mae_scores_sfs = []\n",
        "mse_scores_sfs = []\n",
        "rmse_scores_sfs = []\n",
        "mape_scores_sfs = []\n",
        "r_squared_scores_sfs = []\n",
        "\n",
        "# 오차 비율이 큰 상위 데이터를 저장할 리스트\n",
        "top_errors = []\n",
        "\n",
        "for train_idx, val_idx in k_fold.split(X_selected_sfs):\n",
        "    X_train_fold, X_val_fold = X_selected_sfs[train_idx], X_selected_sfs[val_idx]\n",
        "    y_train_fold, y_val_fold = y_transformed.iloc[train_idx], y_transformed.iloc[val_idx]\n",
        "\n",
        "    knn_model.fit(X_train_fold, y_train_fold)\n",
        "    y_val_pred = knn_model.predict(X_val_fold)\n",
        "\n",
        "    # 예측값과 실제값을 원래 스케일로 되돌리기\n",
        "    y_val_pred_exp = np.expm1(y_val_pred)\n",
        "    y_val_exp = np.expm1(y_val_fold)\n",
        "\n",
        "    mae_scores_sfs.append(mean_absolute_error(y_val_exp, y_val_pred_exp))\n",
        "    mse_scores_sfs.append(mean_squared_error(y_val_exp, y_val_pred_exp))\n",
        "    rmse_scores_sfs.append(np.sqrt(mean_squared_error(y_val_exp, y_val_pred_exp)))\n",
        "    mape_scores_sfs.append(np.mean(np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)) * 100)\n",
        "    r_squared_scores_sfs.append(r2_score(y_val_exp, y_val_pred_exp))\n",
        "\n",
        "    # 오차 비율 계산 및 상위 오차 데이터 저장\n",
        "    error_ratios = np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)\n",
        "    top_error_idx = np.argmax(error_ratios)\n",
        "    top_errors.append({\n",
        "        'Actual': y_val_exp.iloc[top_error_idx],\n",
        "        'Predicted': y_val_pred_exp[top_error_idx],\n",
        "        'Error Ratio': error_ratios.iloc[top_error_idx]\n",
        "    })\n",
        "\n",
        "# 교차 검증 평가 결과 출력\n",
        "results_sfs = {\n",
        "    'MAE': np.mean(mae_scores_sfs),\n",
        "    'MSE': np.mean(mse_scores_sfs),\n",
        "    'RMSE': np.mean(rmse_scores_sfs),\n",
        "    'MAPE': np.mean(mape_scores_sfs),\n",
        "    'R2': np.mean(r_squared_scores_sfs)\n",
        "}\n",
        "print(f\"KNN Results with SequentialFeatureSelector: {results_sfs}\")\n",
        "\n",
        "# 상위 오차 비율 데이터 출력\n",
        "top_errors_sorted = sorted(top_errors, key=lambda x: x['Error Ratio'], reverse=True)[:10]\n",
        "print(\"Top 10 Error Ratios:\")\n",
        "for error_data in top_errors_sorted:\n",
        "    print(f\"Actual: {error_data['Actual']}, Predicted: {error_data['Predicted']}, Error Ratio: {error_data['Error Ratio']}\")"
      ],
      "metadata": {
        "id": "eJtRrPiq-UdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBRegressor예측\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# XGBoost 모델 사용\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "rfe_xgb = RFE(estimator=xgb_model, n_features_to_select=10)\n",
        "fit_xgb = rfe_xgb.fit(X_combined, y_transformed)\n",
        "\n",
        "# 선택된 피처들\n",
        "selected_features_xgb = np.array(combined_feature_names)[fit_xgb.support_]\n",
        "print(f\"Selected features with XGBoost: {selected_features_xgb}\")\n",
        "\n",
        "# 선택된 피처들만 사용하여 데이터프레임 구성\n",
        "X_selected_xgb = X_combined[:, fit_xgb.support_]\n",
        "\n",
        "# 교차 검증을 통한 XGBoost 모델 평가\n",
        "mae_scores_xgb = []\n",
        "mse_scores_xgb = []\n",
        "rmse_scores_xgb = []\n",
        "mape_scores_xgb = []\n",
        "r_squared_scores_xgb = []\n",
        "\n",
        "# 오차 비율이 큰 상위 데이터를 저장할 리스트\n",
        "top_errors_g = []\n",
        "\n",
        "for train_idx, val_idx in k_fold.split(X_selected_xgb):\n",
        "    X_train_fold, X_val_fold = X_selected_xgb[train_idx], X_selected_xgb[val_idx]\n",
        "    y_train_fold, y_val_fold = y_transformed.iloc[train_idx], y_transformed.iloc[val_idx]\n",
        "\n",
        "    xgb_model.fit(X_train_fold, y_train_fold)\n",
        "    y_val_pred = xgb_model.predict(X_val_fold)\n",
        "\n",
        "    # 예측값과 실제값을 원래 스케일로 되돌리기\n",
        "    y_val_pred_exp = np.expm1(y_val_pred)\n",
        "    y_val_exp = np.expm1(y_val_fold)\n",
        "\n",
        "    mae_scores_xgb.append(mean_absolute_error(y_val_exp, y_val_pred_exp))\n",
        "    mse_scores_xgb.append(mean_squared_error(y_val_exp, y_val_pred_exp))\n",
        "    rmse_scores_xgb.append(np.sqrt(mean_squared_error(y_val_exp, y_val_pred_exp)))\n",
        "    mape_scores_xgb.append(np.mean(np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)) * 100)\n",
        "    r_squared_scores_xgb.append(r2_score(y_val_exp, y_val_pred_exp))\n",
        "\n",
        "    # 오차 비율 계산 및 상위 오차 데이터 저장\n",
        "    error_ratios_g = np.abs((y_val_exp - y_val_pred_exp) / y_val_exp)\n",
        "    top_error_idx_g = np.argmax(error_ratios_g)\n",
        "    top_errors_g.append({\n",
        "        'Actual': y_val_exp.iloc[top_error_idx_g],\n",
        "        'Predicted': y_val_pred_exp[top_error_idx_g],\n",
        "        'Error Ratio': error_ratios_g.iloc[top_error_idx_g]\n",
        "    })\n",
        "\n",
        "# 교차 검증 평가 결과 출력\n",
        "results_xgb = {\n",
        "    'MAE': np.mean(mae_scores_xgb),\n",
        "    'MSE': np.mean(mse_scores_xgb),\n",
        "    'RMSE': np.mean(rmse_scores_xgb),\n",
        "    'MAPE': np.mean(mape_scores_xgb),\n",
        "    'R2': np.mean(r_squared_scores_xgb)\n",
        "}\n",
        "print(f\"XGBoost Results: {results_xgb}\")\n",
        "# 상위 오차 비율 데이터 출력\n",
        "top_errors_sorted_g = sorted(top_errors_g, key=lambda x: x['Error Ratio'], reverse=True)[:10]\n",
        "print(\"Top 10 Error Ratios:\")\n",
        "for error_data in top_errors_sorted_g:\n",
        "    print(f\"Actual: {error_data['Actual']}, Predicted: {error_data['Predicted']}, Error Ratio: {error_data['Error Ratio']}\")"
      ],
      "metadata": {
        "id": "7SXYVaIt-Wig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}